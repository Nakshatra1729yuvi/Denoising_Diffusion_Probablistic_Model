{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Model"
      ],
      "metadata": {
        "id": "PNTsKWpwDRRi"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "Vu6Z_5Pwyz2p"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class LinearNoiseScheduler:\n",
        "\n",
        "  def __init__(self,beta_start,beta_end,num_timesteps):\n",
        "    self.beta_start=beta_start\n",
        "    self.beta_end=beta_end\n",
        "    self.num_timesteps=num_timesteps\n",
        "\n",
        "    self.betas=torch.linspace(beta_start,beta_end,num_timesteps)\n",
        "\n",
        "    self.alphas=1-self.betas\n",
        "    self.sqrt_alphas=torch.sqrt(self.alphas)\n",
        "    self.alphas_cum_prod=torch.cumprod(self.alphas ,dim=0)\n",
        "    self.sqrt_alphas_cum_prod=torch.sqrt(self.alphas_cum_prod)\n",
        "    self.sqrt_one_minus_alphas_cum_prod=torch.sqrt(1-self.alphas_cum_prod)\n",
        "\n",
        "  def add_noise(self,original,noise,t):\n",
        "\n",
        "    sqrt_alphas_cum_prod=self.sqrt_alphas_cum_prod.to(original.device)[t].view(-1,1,1,1)\n",
        "    sqrt_one_minus_alphas_cum_prod=self.sqrt_one_minus_alphas_cum_prod.to(original.device)[t].view(-1,1,1,1)\n",
        "\n",
        "    return sqrt_alphas_cum_prod*original+sqrt_one_minus_alphas_cum_prod*noise\n",
        "\n",
        "  def sample_prev_timestep(self,xt,noise_pred,t):\n",
        "\n",
        "    x0=xt-(self.sqrt_one_minus_alphas_cum_prod.to(xt.device)[t])*noise_pred\n",
        "    x0=x0/self.sqrt_alphas_cum_prod.to(xt.device)[t]\n",
        "    x0=torch.clamp(x0,-1,1)\n",
        "\n",
        "\n",
        "    mean=xt-(self.betas.to(xt.device)[t]/self.sqrt_one_minus_alphas_cum_prod.to(xt.device)[t])*noise_pred\n",
        "    mean=mean/self.sqrt_alphas.to(xt.device)[t]\n",
        "\n",
        "    if t==0:\n",
        "      return mean, x0\n",
        "    else:\n",
        "      variance=(self.sqrt_one_minus_alphas_cum_prod.to(xt.device)[t-1])/(self.sqrt_one_minus_alphas_cum_prod.to(xt.device)[t])\n",
        "      sigma=(self.betas.to(xt.device)[t]**0.5)*variance\n",
        "      z=torch.randn(xt.shape).to(xt.device)\n",
        "\n",
        "      return mean+sigma*z,x0\n"
      ],
      "metadata": {
        "id": "BETh8hWGy-ki"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_time_embedding(time_steps,t_emb_dim):\n",
        "\n",
        "  assert t_emb_dim%2==0\n",
        "\n",
        "  factor=1000**(torch.arange(0,t_emb_dim//2,dtype=torch.float32,device=time_steps.device)/(t_emb_dim//2))\n",
        "\n",
        "  t_emb=time_steps.view(-1,1)/factor\n",
        "  t_emb=torch.concat([torch.sin(t_emb),torch.cos(t_emb)],dim=-1)\n",
        "\n",
        "  return t_emb"
      ],
      "metadata": {
        "id": "QTn1QlGwY-6K"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DownSample(nn.Module):\n",
        "  def __init__(self,in_channels,hidden_channels,emb_dim,downsample,num_layers=1,num_heads=4):\n",
        "    super().__init__()\n",
        "\n",
        "    self.downsample=downsample\n",
        "    self.num_layers=num_layers\n",
        "    self.resnet_first=nn.ModuleList(nn.Sequential(\n",
        "        nn.GroupNorm(8,in_channels if i==0 else hidden_channels),\n",
        "        nn.SiLU(),\n",
        "        nn.Conv2d(in_channels if i==0 else hidden_channels,hidden_channels,kernel_size=3,stride=1,padding=1)\n",
        "    ) for i in range(num_layers)\n",
        "    )\n",
        "\n",
        "    self.t_emb_layers=nn.ModuleList(\n",
        "        nn.Sequential(\n",
        "            nn.SiLU(),\n",
        "            nn.Linear(emb_dim,hidden_channels)\n",
        "        ) for i in range(num_layers)\n",
        "    )\n",
        "\n",
        "    self.resnet_second=nn.ModuleList(nn.Sequential(\n",
        "        nn.GroupNorm(8,hidden_channels),\n",
        "        nn.SiLU(),\n",
        "        nn.Conv2d(hidden_channels,hidden_channels,kernel_size=3,stride=1,padding=1)\n",
        "    ) for i in range(num_layers)\n",
        "    )\n",
        "\n",
        "    self.attn_norms=nn.ModuleList([nn.GroupNorm(8,hidden_channels) for _ in range(num_layers)])\n",
        "\n",
        "    self.attns=nn.ModuleList([nn.MultiheadAttention(hidden_channels,num_heads,batch_first=True) for _ in range(num_layers)])\n",
        "\n",
        "    self.resnet_input=nn.ModuleList([nn.Conv2d(in_channels if i==0 else hidden_channels,hidden_channels,kernel_size=3,stride=1,padding=1) for i in range(num_layers)])\n",
        "\n",
        "    self.downsample_conv=nn.Conv2d(hidden_channels,hidden_channels,kernel_size=4,stride=2,padding=1)\n",
        "\n",
        "  def forward(self,x,t_emb):\n",
        "    out=x\n",
        "    for i in range(self.num_layers):\n",
        "\n",
        "      resnet_input=out\n",
        "      out=self.resnet_first[i](resnet_input)\n",
        "      out=out+self.t_emb_layers[i](t_emb)[:,:,None,None]\n",
        "      out=self.resnet_second[i](out)\n",
        "      out=out+self.resnet_input[i](resnet_input)\n",
        "\n",
        "      B,C,H,W=out.shape\n",
        "      attn=out.reshape(B,C,H*W)\n",
        "      attn=self.attn_norms[i](attn)\n",
        "      attn=attn.transpose(1,2)\n",
        "      attn,_=self.attns[i](attn,attn,attn)\n",
        "      attn=attn.transpose(1,2).reshape(B,C,H,W)\n",
        "      out=out+attn\n",
        "\n",
        "\n",
        "\n",
        "    return self.downsample_conv(out) if self.downsample else out\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "J-zK93N1e0hi"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MidBlock(nn.Module):\n",
        "  def __init__(self,in_channels,hidden_channels,emb_dim,num_layers=1,num_heads=4):\n",
        "    super().__init__()\n",
        "\n",
        "\n",
        "    self.num_layers=num_layers\n",
        "    self.resnet_first=nn.ModuleList(nn.Sequential(\n",
        "        nn.GroupNorm(8,in_channels if i==0 else hidden_channels),\n",
        "        nn.SiLU(),\n",
        "        nn.Conv2d(in_channels if i==0 else hidden_channels,hidden_channels,kernel_size=3,stride=1,padding=1)\n",
        "    ) for i in range(num_layers+1)\n",
        "    )\n",
        "\n",
        "    self.t_emb_layers=nn.ModuleList(\n",
        "        nn.Sequential(\n",
        "            nn.SiLU(),\n",
        "            nn.Linear(emb_dim,hidden_channels)\n",
        "        ) for i in range(num_layers+1)\n",
        "    )\n",
        "\n",
        "    self.resnet_second=nn.ModuleList(nn.Sequential(\n",
        "        nn.GroupNorm(8,hidden_channels),\n",
        "        nn.SiLU(),\n",
        "        nn.Conv2d(hidden_channels,hidden_channels,kernel_size=3,stride=1,padding=1)\n",
        "    ) for i in range(num_layers+1)\n",
        "    )\n",
        "\n",
        "    self.attn_norms=nn.ModuleList([nn.GroupNorm(8,hidden_channels) for _ in range(num_layers)])\n",
        "\n",
        "    self.attns=nn.ModuleList([nn.MultiheadAttention(hidden_channels,num_heads,batch_first=True) for _ in range(num_layers)])\n",
        "\n",
        "    self.resnet_input=nn.ModuleList([nn.Conv2d(in_channels if i==0 else hidden_channels,hidden_channels,kernel_size=3,stride=1,padding=1) for i in range(num_layers+1)])\n",
        "\n",
        "\n",
        "  def forward(self,x,t_emb):\n",
        "    out=x\n",
        "\n",
        "    resnet_input=out\n",
        "\n",
        "    out=self.resnet_first[0](resnet_input)\n",
        "    out=out+self.t_emb_layers[0](t_emb)[:,:,None,None]\n",
        "    out=self.resnet_second[0](out)\n",
        "    out=out+self.resnet_input[0](resnet_input)\n",
        "\n",
        "    for i in range(self.num_layers):\n",
        "\n",
        "      B,C,H,W=out.shape\n",
        "      attn=out.reshape(B,C,H*W)\n",
        "      attn=self.attn_norms[i](attn)\n",
        "      attn=attn.transpose(1,2)\n",
        "      attn,_=self.attns[i](attn,attn,attn)\n",
        "      attn=attn.transpose(1,2).reshape(B,C,H,W)\n",
        "      out=out+attn\n",
        "\n",
        "      resnet_input=out\n",
        "      out=self.resnet_first[i+1](resnet_input)\n",
        "      out=out+self.t_emb_layers[i+1](t_emb)[:,:,None,None]\n",
        "      out=self.resnet_second[i+1](out)\n",
        "      out=out+self.resnet_input[i+1](resnet_input)\n",
        "\n",
        "\n",
        "    return out\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "AaeH3RHNySRq"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class UpSample(nn.Module):\n",
        "  def __init__(self,in_channels,hidden_channels,emb_dim,upsample,num_layers=1,num_heads=4):\n",
        "    super().__init__()\n",
        "\n",
        "    self.upsample=upsample\n",
        "    self.upsample_conv=nn.ConvTranspose2d(in_channels,in_channels//2,kernel_size=4,stride=2,padding=1)\n",
        "\n",
        "    self.num_layers=num_layers\n",
        "    self.resnet_first=nn.ModuleList(nn.Sequential(\n",
        "        nn.GroupNorm(8,in_channels if i==0 else hidden_channels),\n",
        "        nn.SiLU(),\n",
        "        nn.Conv2d(in_channels if i==0 else hidden_channels,hidden_channels,kernel_size=3,stride=1,padding=1)\n",
        "    ) for i in range(num_layers)\n",
        "    )\n",
        "\n",
        "    self.t_emb_layers=nn.ModuleList(\n",
        "        nn.Sequential(\n",
        "            nn.SiLU(),\n",
        "            nn.Linear(emb_dim,hidden_channels)\n",
        "        ) for i in range(num_layers)\n",
        "    )\n",
        "\n",
        "    self.resnet_second=nn.ModuleList(nn.Sequential(\n",
        "        nn.GroupNorm(8,hidden_channels),\n",
        "        nn.SiLU(),\n",
        "        nn.Conv2d(hidden_channels,hidden_channels,kernel_size=3,stride=1,padding=1)\n",
        "    ) for i in range(num_layers)\n",
        "    )\n",
        "\n",
        "    self.attn_norms=nn.ModuleList([nn.GroupNorm(8,hidden_channels) for _ in range(num_layers)])\n",
        "\n",
        "    self.attns=nn.ModuleList([nn.MultiheadAttention(hidden_channels,num_heads,batch_first=True) for _ in range(num_layers)])\n",
        "\n",
        "    self.resnet_input=nn.ModuleList([nn.Conv2d(in_channels if i==0 else hidden_channels,hidden_channels,kernel_size=3,stride=1,padding=1) for i in range(num_layers)])\n",
        "\n",
        "\n",
        "\n",
        "  def forward(self,x,out_down,t_emb):\n",
        "    x=self.upsample_conv(x) if self.upsample else x\n",
        "    x=torch.cat([x,out_down],dim=1)\n",
        "    out=x\n",
        "    for i in range(self.num_layers):\n",
        "\n",
        "      resnet_input=out\n",
        "      out=self.resnet_first[i](resnet_input)\n",
        "      out=out+self.t_emb_layers[i](t_emb)[:,:,None,None]\n",
        "      out=self.resnet_second[i](out)\n",
        "      out=out+self.resnet_input[i](resnet_input)\n",
        "\n",
        "      B,C,H,W=out.shape\n",
        "      attn=out.reshape(B,C,H*W)\n",
        "      attn=self.attn_norms[i](attn)\n",
        "      attn=attn.transpose(1,2)\n",
        "      attn,_=self.attns[i](attn,attn,attn)\n",
        "      attn=attn.transpose(1,2).reshape(B,C,H,W)\n",
        "      out=out+attn\n",
        "\n",
        "\n",
        "\n",
        "    return out\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "wTjZiGWaz5Ba"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Unet(nn.Module):\n",
        "  def __init__(self,in_channels):\n",
        "    super().__init__()\n",
        "    self.down_channels=[32,64,128,256]\n",
        "    self.mid_channels=[256,256,128]\n",
        "    self.up_channels=[256,128,64,32]\n",
        "    self.down_bool=[True,True,False]\n",
        "    self.up_bool=[False,True,True]\n",
        "    self.t_emb_dim=128\n",
        "\n",
        "    self.in_conv=nn.Conv2d(in_channels=in_channels,out_channels=self.down_channels[0],kernel_size=3,stride=1,padding=1)\n",
        "\n",
        "    self.downs=nn.ModuleList([])\n",
        "    self.mids=nn.ModuleList([])\n",
        "    self.ups=nn.ModuleList([])\n",
        "\n",
        "    for i in range(len(self.down_channels)-1):\n",
        "      self.downs.append(DownSample(self.down_channels[i],self.down_channels[i+1],self.t_emb_dim,self.down_bool[i]))\n",
        "\n",
        "    for i in range(len(self.mid_channels)-1):\n",
        "      self.mids.append(MidBlock(self.mid_channels[i],self.mid_channels[i+1],self.t_emb_dim))\n",
        "\n",
        "    for i in range(len(self.up_channels)-1):\n",
        "      self.ups.append(UpSample(self.up_channels[i],self.up_channels[i+1],self.t_emb_dim,self.up_bool[i]))\n",
        "\n",
        "    self.t_proj=nn.Sequential(\n",
        "        nn.Linear(self.t_emb_dim,self.t_emb_dim),\n",
        "        nn.SiLU(),\n",
        "        nn.Linear(self.t_emb_dim,self.t_emb_dim)\n",
        "    )\n",
        "    self.norm_out=nn.GroupNorm(8,self.up_channels[-1])\n",
        "    self.conv_out=nn.Conv2d(self.up_channels[-1],in_channels,kernel_size=3,stride=1,padding=1)\n",
        "\n",
        "  def forward(self,x,t):\n",
        "\n",
        "    out=self.in_conv(x)\n",
        "    t_emb=get_time_embedding(t,self.t_emb_dim)\n",
        "    t_emb=self.t_proj(t_emb)\n",
        "\n",
        "    down_outs=[]\n",
        "\n",
        "    for i in range(len(self.downs)):\n",
        "      down_outs.append(out)\n",
        "      out=self.downs[i](out,t_emb)\n",
        "\n",
        "    for i in range(len(self.mids)):\n",
        "      out=self.mids[i](out,t_emb)\n",
        "\n",
        "    for i in range(len(self.ups)):\n",
        "      skip=down_outs.pop()\n",
        "      out=self.ups[i](out,skip,t_emb)\n",
        "\n",
        "    out=self.norm_out(out)\n",
        "    return self.conv_out(out)\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "NXHQFK9I3CGs"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision.datasets import MNIST\n",
        "import torchvision.transforms as T\n",
        "from torch.utils.data import DataLoader\n",
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "BvDBNh-nIXre"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device=torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "metadata": {
        "id": "jRSdNluAK1aY"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transform=T.Compose([\n",
        "    T.ToTensor(),\n",
        "    T.Lambda(lambda x: 2*x-1)\n",
        "])\n",
        "train_ds=MNIST(root='/data',train=True,transform=transform,download=True)\n",
        "train_loader=DataLoader(train_ds,32,shuffle=True)"
      ],
      "metadata": {
        "id": "l5iZH2etIZ0b"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "time_steps=500\n",
        "time_scheduler=LinearNoiseScheduler(beta_start=1e-4,beta_end=0.02,num_timesteps=time_steps)"
      ],
      "metadata": {
        "id": "ZROhh4IQJyKC"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model=Unet(1).to(device)"
      ],
      "metadata": {
        "id": "0bhSxhD9KSV3"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# model.load_state_dict(torch.load('ddpm.pth',map_location=device))"
      ],
      "metadata": {
        "id": "WITwIsmZf-YG"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "p=0\n",
        "print(\"Parameters per layer:\")\n",
        "for name, parameter in model.named_parameters():\n",
        "    params = parameter.numel()\n",
        "    p+=params\n",
        "    print(f\"- {name}: {params}\")\n",
        "print(f\"Total no. of Parameters:{p}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tg-UK082DrqI",
        "outputId": "a10f6774-e07e-469e-e172-d125ccc68cf2"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parameters per layer:\n",
            "- in_conv.weight: 288\n",
            "- in_conv.bias: 32\n",
            "- downs.0.resnet_first.0.0.weight: 32\n",
            "- downs.0.resnet_first.0.0.bias: 32\n",
            "- downs.0.resnet_first.0.2.weight: 18432\n",
            "- downs.0.resnet_first.0.2.bias: 64\n",
            "- downs.0.t_emb_layers.0.1.weight: 8192\n",
            "- downs.0.t_emb_layers.0.1.bias: 64\n",
            "- downs.0.resnet_second.0.0.weight: 64\n",
            "- downs.0.resnet_second.0.0.bias: 64\n",
            "- downs.0.resnet_second.0.2.weight: 36864\n",
            "- downs.0.resnet_second.0.2.bias: 64\n",
            "- downs.0.attn_norms.0.weight: 64\n",
            "- downs.0.attn_norms.0.bias: 64\n",
            "- downs.0.attns.0.in_proj_weight: 12288\n",
            "- downs.0.attns.0.in_proj_bias: 192\n",
            "- downs.0.attns.0.out_proj.weight: 4096\n",
            "- downs.0.attns.0.out_proj.bias: 64\n",
            "- downs.0.resnet_input.0.weight: 18432\n",
            "- downs.0.resnet_input.0.bias: 64\n",
            "- downs.0.downsample_conv.weight: 65536\n",
            "- downs.0.downsample_conv.bias: 64\n",
            "- downs.1.resnet_first.0.0.weight: 64\n",
            "- downs.1.resnet_first.0.0.bias: 64\n",
            "- downs.1.resnet_first.0.2.weight: 73728\n",
            "- downs.1.resnet_first.0.2.bias: 128\n",
            "- downs.1.t_emb_layers.0.1.weight: 16384\n",
            "- downs.1.t_emb_layers.0.1.bias: 128\n",
            "- downs.1.resnet_second.0.0.weight: 128\n",
            "- downs.1.resnet_second.0.0.bias: 128\n",
            "- downs.1.resnet_second.0.2.weight: 147456\n",
            "- downs.1.resnet_second.0.2.bias: 128\n",
            "- downs.1.attn_norms.0.weight: 128\n",
            "- downs.1.attn_norms.0.bias: 128\n",
            "- downs.1.attns.0.in_proj_weight: 49152\n",
            "- downs.1.attns.0.in_proj_bias: 384\n",
            "- downs.1.attns.0.out_proj.weight: 16384\n",
            "- downs.1.attns.0.out_proj.bias: 128\n",
            "- downs.1.resnet_input.0.weight: 73728\n",
            "- downs.1.resnet_input.0.bias: 128\n",
            "- downs.1.downsample_conv.weight: 262144\n",
            "- downs.1.downsample_conv.bias: 128\n",
            "- downs.2.resnet_first.0.0.weight: 128\n",
            "- downs.2.resnet_first.0.0.bias: 128\n",
            "- downs.2.resnet_first.0.2.weight: 294912\n",
            "- downs.2.resnet_first.0.2.bias: 256\n",
            "- downs.2.t_emb_layers.0.1.weight: 32768\n",
            "- downs.2.t_emb_layers.0.1.bias: 256\n",
            "- downs.2.resnet_second.0.0.weight: 256\n",
            "- downs.2.resnet_second.0.0.bias: 256\n",
            "- downs.2.resnet_second.0.2.weight: 589824\n",
            "- downs.2.resnet_second.0.2.bias: 256\n",
            "- downs.2.attn_norms.0.weight: 256\n",
            "- downs.2.attn_norms.0.bias: 256\n",
            "- downs.2.attns.0.in_proj_weight: 196608\n",
            "- downs.2.attns.0.in_proj_bias: 768\n",
            "- downs.2.attns.0.out_proj.weight: 65536\n",
            "- downs.2.attns.0.out_proj.bias: 256\n",
            "- downs.2.resnet_input.0.weight: 294912\n",
            "- downs.2.resnet_input.0.bias: 256\n",
            "- downs.2.downsample_conv.weight: 1048576\n",
            "- downs.2.downsample_conv.bias: 256\n",
            "- mids.0.resnet_first.0.0.weight: 256\n",
            "- mids.0.resnet_first.0.0.bias: 256\n",
            "- mids.0.resnet_first.0.2.weight: 589824\n",
            "- mids.0.resnet_first.0.2.bias: 256\n",
            "- mids.0.resnet_first.1.0.weight: 256\n",
            "- mids.0.resnet_first.1.0.bias: 256\n",
            "- mids.0.resnet_first.1.2.weight: 589824\n",
            "- mids.0.resnet_first.1.2.bias: 256\n",
            "- mids.0.t_emb_layers.0.1.weight: 32768\n",
            "- mids.0.t_emb_layers.0.1.bias: 256\n",
            "- mids.0.t_emb_layers.1.1.weight: 32768\n",
            "- mids.0.t_emb_layers.1.1.bias: 256\n",
            "- mids.0.resnet_second.0.0.weight: 256\n",
            "- mids.0.resnet_second.0.0.bias: 256\n",
            "- mids.0.resnet_second.0.2.weight: 589824\n",
            "- mids.0.resnet_second.0.2.bias: 256\n",
            "- mids.0.resnet_second.1.0.weight: 256\n",
            "- mids.0.resnet_second.1.0.bias: 256\n",
            "- mids.0.resnet_second.1.2.weight: 589824\n",
            "- mids.0.resnet_second.1.2.bias: 256\n",
            "- mids.0.attn_norms.0.weight: 256\n",
            "- mids.0.attn_norms.0.bias: 256\n",
            "- mids.0.attns.0.in_proj_weight: 196608\n",
            "- mids.0.attns.0.in_proj_bias: 768\n",
            "- mids.0.attns.0.out_proj.weight: 65536\n",
            "- mids.0.attns.0.out_proj.bias: 256\n",
            "- mids.0.resnet_input.0.weight: 589824\n",
            "- mids.0.resnet_input.0.bias: 256\n",
            "- mids.0.resnet_input.1.weight: 589824\n",
            "- mids.0.resnet_input.1.bias: 256\n",
            "- mids.1.resnet_first.0.0.weight: 256\n",
            "- mids.1.resnet_first.0.0.bias: 256\n",
            "- mids.1.resnet_first.0.2.weight: 294912\n",
            "- mids.1.resnet_first.0.2.bias: 128\n",
            "- mids.1.resnet_first.1.0.weight: 128\n",
            "- mids.1.resnet_first.1.0.bias: 128\n",
            "- mids.1.resnet_first.1.2.weight: 147456\n",
            "- mids.1.resnet_first.1.2.bias: 128\n",
            "- mids.1.t_emb_layers.0.1.weight: 16384\n",
            "- mids.1.t_emb_layers.0.1.bias: 128\n",
            "- mids.1.t_emb_layers.1.1.weight: 16384\n",
            "- mids.1.t_emb_layers.1.1.bias: 128\n",
            "- mids.1.resnet_second.0.0.weight: 128\n",
            "- mids.1.resnet_second.0.0.bias: 128\n",
            "- mids.1.resnet_second.0.2.weight: 147456\n",
            "- mids.1.resnet_second.0.2.bias: 128\n",
            "- mids.1.resnet_second.1.0.weight: 128\n",
            "- mids.1.resnet_second.1.0.bias: 128\n",
            "- mids.1.resnet_second.1.2.weight: 147456\n",
            "- mids.1.resnet_second.1.2.bias: 128\n",
            "- mids.1.attn_norms.0.weight: 128\n",
            "- mids.1.attn_norms.0.bias: 128\n",
            "- mids.1.attns.0.in_proj_weight: 49152\n",
            "- mids.1.attns.0.in_proj_bias: 384\n",
            "- mids.1.attns.0.out_proj.weight: 16384\n",
            "- mids.1.attns.0.out_proj.bias: 128\n",
            "- mids.1.resnet_input.0.weight: 294912\n",
            "- mids.1.resnet_input.0.bias: 128\n",
            "- mids.1.resnet_input.1.weight: 147456\n",
            "- mids.1.resnet_input.1.bias: 128\n",
            "- ups.0.upsample_conv.weight: 524288\n",
            "- ups.0.upsample_conv.bias: 128\n",
            "- ups.0.resnet_first.0.0.weight: 256\n",
            "- ups.0.resnet_first.0.0.bias: 256\n",
            "- ups.0.resnet_first.0.2.weight: 294912\n",
            "- ups.0.resnet_first.0.2.bias: 128\n",
            "- ups.0.t_emb_layers.0.1.weight: 16384\n",
            "- ups.0.t_emb_layers.0.1.bias: 128\n",
            "- ups.0.resnet_second.0.0.weight: 128\n",
            "- ups.0.resnet_second.0.0.bias: 128\n",
            "- ups.0.resnet_second.0.2.weight: 147456\n",
            "- ups.0.resnet_second.0.2.bias: 128\n",
            "- ups.0.attn_norms.0.weight: 128\n",
            "- ups.0.attn_norms.0.bias: 128\n",
            "- ups.0.attns.0.in_proj_weight: 49152\n",
            "- ups.0.attns.0.in_proj_bias: 384\n",
            "- ups.0.attns.0.out_proj.weight: 16384\n",
            "- ups.0.attns.0.out_proj.bias: 128\n",
            "- ups.0.resnet_input.0.weight: 294912\n",
            "- ups.0.resnet_input.0.bias: 128\n",
            "- ups.1.upsample_conv.weight: 131072\n",
            "- ups.1.upsample_conv.bias: 64\n",
            "- ups.1.resnet_first.0.0.weight: 128\n",
            "- ups.1.resnet_first.0.0.bias: 128\n",
            "- ups.1.resnet_first.0.2.weight: 73728\n",
            "- ups.1.resnet_first.0.2.bias: 64\n",
            "- ups.1.t_emb_layers.0.1.weight: 8192\n",
            "- ups.1.t_emb_layers.0.1.bias: 64\n",
            "- ups.1.resnet_second.0.0.weight: 64\n",
            "- ups.1.resnet_second.0.0.bias: 64\n",
            "- ups.1.resnet_second.0.2.weight: 36864\n",
            "- ups.1.resnet_second.0.2.bias: 64\n",
            "- ups.1.attn_norms.0.weight: 64\n",
            "- ups.1.attn_norms.0.bias: 64\n",
            "- ups.1.attns.0.in_proj_weight: 12288\n",
            "- ups.1.attns.0.in_proj_bias: 192\n",
            "- ups.1.attns.0.out_proj.weight: 4096\n",
            "- ups.1.attns.0.out_proj.bias: 64\n",
            "- ups.1.resnet_input.0.weight: 73728\n",
            "- ups.1.resnet_input.0.bias: 64\n",
            "- ups.2.upsample_conv.weight: 32768\n",
            "- ups.2.upsample_conv.bias: 32\n",
            "- ups.2.resnet_first.0.0.weight: 64\n",
            "- ups.2.resnet_first.0.0.bias: 64\n",
            "- ups.2.resnet_first.0.2.weight: 18432\n",
            "- ups.2.resnet_first.0.2.bias: 32\n",
            "- ups.2.t_emb_layers.0.1.weight: 4096\n",
            "- ups.2.t_emb_layers.0.1.bias: 32\n",
            "- ups.2.resnet_second.0.0.weight: 32\n",
            "- ups.2.resnet_second.0.0.bias: 32\n",
            "- ups.2.resnet_second.0.2.weight: 9216\n",
            "- ups.2.resnet_second.0.2.bias: 32\n",
            "- ups.2.attn_norms.0.weight: 32\n",
            "- ups.2.attn_norms.0.bias: 32\n",
            "- ups.2.attns.0.in_proj_weight: 3072\n",
            "- ups.2.attns.0.in_proj_bias: 96\n",
            "- ups.2.attns.0.out_proj.weight: 1024\n",
            "- ups.2.attns.0.out_proj.bias: 32\n",
            "- ups.2.resnet_input.0.weight: 18432\n",
            "- ups.2.resnet_input.0.bias: 32\n",
            "- t_proj.0.weight: 16384\n",
            "- t_proj.0.bias: 128\n",
            "- t_proj.2.weight: 16384\n",
            "- t_proj.2.bias: 128\n",
            "- norm_out.weight: 32\n",
            "- norm_out.bias: 32\n",
            "- conv_out.weight: 288\n",
            "- conv_out.bias: 1\n",
            "Total no. of Parameters:10293505\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "crit=nn.MSELoss()"
      ],
      "metadata": {
        "id": "5DKwSCnKL_ln"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer=torch.optim.AdamW(model.parameters(),lr=1e-4)"
      ],
      "metadata": {
        "id": "rOGFRXALKV6D"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs=0\n",
        "for epoch in range(epochs):\n",
        "  for x,_ in tqdm(train_loader):\n",
        "    x=x.to(device)\n",
        "\n",
        "    B=x.shape[0]\n",
        "\n",
        "    t=torch.randint(0,time_steps,(B,),device=x.device)\n",
        "\n",
        "    noise=torch.randn_like(x)\n",
        "\n",
        "    x_t=time_scheduler.add_noise(x,noise,t)\n",
        "    noise_pred=model(x_t,t)\n",
        "    loss=crit(noise,noise_pred)\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "  print(f\"Epochs:{epoch+1},Loss:{loss.item()}\")\n"
      ],
      "metadata": {
        "id": "mU2znNqBLIop"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# inference"
      ],
      "metadata": {
        "id": "LGN7RkapOHEH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# inference\n",
        "\n",
        "img_stack=[]\n",
        "x=torch.randn(1,1,28,28).to(device)\n",
        "for t in tqdm(range(time_steps)):\n",
        "  t_tensor = torch.full((x.shape[0],), 499 - t, device=x.device)\n",
        "  noise_pred=model(x,t_tensor)\n",
        "  x,_=time_scheduler.sample_prev_timestep(x,noise_pred,t_tensor)\n",
        "  if (t+1)%500==0:\n",
        "        img_stack.append(x.detach().cpu())\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Show images every 100 steps\n",
        "for i in range(len(img_stack)):  # 99, 199, 299 ... for 100th, 200th, etc.\n",
        "    img = (img_stack[i][0, 0] + 1) / 2  # normalize to [0,1]\n",
        "    plt.figure()\n",
        "    plt.imshow(img, cmap='gray')\n",
        "    plt.title(f\"Step {i+1}\")\n",
        "    plt.axis('off')\n",
        "    plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        },
        "id": "gbh1L23rOFKT",
        "outputId": "5c544103-1964-45ad-aa8f-3ad04333cad4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 99%|█████████▉| 497/500 [00:08<00:00, 55.54it/s]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "OutOfMemoryError",
          "evalue": "CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.74 GiB of which 4.12 MiB is free. Process 12891 has 14.73 GiB memory in use. Of the allocated memory 13.97 GiB is allocated by PyTorch, and 650.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-4237645306.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime_steps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m   \u001b[0mt_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfull\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m499\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m   \u001b[0mnoise_pred\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mt_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m   \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0m_\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtime_scheduler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_prev_timestep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnoise_pred\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mt_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1773\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1774\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1775\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1776\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1777\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1784\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1785\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1786\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1787\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1788\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-3911606222.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, t)\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mups\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m       \u001b[0mskip\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdown_outs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m       \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mups\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mskip\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mt_emb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm_out\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1773\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1774\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1775\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1776\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1777\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1784\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1785\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1786\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1787\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1788\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-2405162919.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, out_down, t_emb)\u001b[0m\n\u001b[1;32m     52\u001b[0m       \u001b[0mattn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattn_norms\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m       \u001b[0mattn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m       \u001b[0mattn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0m_\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattns\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mattn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mattn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m       \u001b[0mattn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mB\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mC\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mH\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mW\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m       \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mattn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1773\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1774\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1775\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1776\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1777\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1784\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1785\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1786\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1787\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1788\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/activation.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, query, key, value, key_padding_mask, need_weights, attn_mask, average_attn_weights, is_causal)\u001b[0m\n\u001b[1;32m   1486\u001b[0m             )\n\u001b[1;32m   1487\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1488\u001b[0;31m             attn_output, attn_output_weights = F.multi_head_attention_forward(\n\u001b[0m\u001b[1;32m   1489\u001b[0m                 \u001b[0mquery\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1490\u001b[0m                 \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mmulti_head_attention_forward\u001b[0;34m(query, key, value, embed_dim_to_check, num_heads, in_proj_weight, in_proj_bias, bias_k, bias_v, add_zero_attn, dropout_p, out_proj_weight, out_proj_bias, training, key_padding_mask, need_weights, attn_mask, use_separate_proj_weight, q_proj_weight, k_proj_weight, v_proj_weight, static_k, static_v, average_attn_weights, is_causal)\u001b[0m\n\u001b[1;32m   6449\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6450\u001b[0m             \u001b[0mattn_output_weights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq_scaled\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6451\u001b[0;31m         \u001b[0mattn_output_weights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattn_output_weights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6452\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mdropout_p\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6453\u001b[0m             \u001b[0mattn_output_weights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattn_output_weights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdropout_p\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36msoftmax\u001b[0;34m(input, dim, _stacklevel, dtype)\u001b[0m\n\u001b[1;32m   2131\u001b[0m         \u001b[0mdim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_softmax_dim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"softmax\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_stacklevel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2132\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2133\u001b[0;31m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2134\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2135\u001b[0m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 20.00 MiB. GPU 0 has a total capacity of 14.74 GiB of which 4.12 MiB is free. Process 12891 has 14.73 GiB memory in use. Of the allocated memory 13.97 GiB is allocated by PyTorch, and 650.78 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
          ]
        }
      ]
    }
  ]
}